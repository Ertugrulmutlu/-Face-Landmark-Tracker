# ğŸ¯ Face Landmarks Detection (OpenCV DNN + Facemark)

This project detects faces in a video, extracts **68 facial landmarks**, and saves them into:

* an **annotated output video**
* an optional **CSV file** containing all landmarks per frame

Built with **OpenCV (DNN + Facemark LBF)** and includes smoothing for stable tracking.

---

## âš¡ Features

* Face detection with **OpenCV DNN** (ResNet SSD Caffe model)
* 68-point landmark detection with **Facemark LBF**
* Optional CSV export (`x0..x67, y0..y67`)
* **EMA smoothing filter** to stabilize jitter
* Configurable input/output paths & frame skipping

---

## ğŸš€ Setup

1. Clone this repository:

   ```bash
   git clone https://github.com/yourusername/face-landmarks-detection.git
   cd face-landmarks-detection
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

   or manually:

   ```bash
   pip install opencv-contrib-python numpy
   ```

3. Download the required model files:

   * **Facial landmark model (LBF):**
     [lbfmodel.yaml](https://github.com/kurnianggoro/GSOC2017/blob/master/data/lbfmodel.yaml)

   * **Face detector weights:**
     [res10\_300x300\_ssd\_iter\_140000\_fp16.caffemodel](https://github.com/mostofashakib/Image-Analysis-and-Real-Time-Face-Recognition-system/blob/master/res10_300x300_ssd_iter_140000_fp16.caffemodel)

   * **Face detector config:**
     [deploy.prototxt](https://github.com/opencv/opencv/blob/master/samples/dnn/face_detector/deploy.prototxt)

   Save them under a `model/` directory:

   ```
   model/
   â”œâ”€â”€ lbfmodel.yaml
   â”œâ”€â”€ res10_300x300_ssd_iter_140000_fp16.caffemodel
   â””â”€â”€ deploy.prototxt
   ```

---

## â–¶ï¸ Usage

Put your input video inside a `video/` folder, e.g.:

```
video/example.mp4
```

Run the script:

```bash
python main.py
```

Outputs:

* Annotated video â†’ `./output/annotated.mp4`
* Landmark CSV (if enabled) â†’ `./output/landmarks.csv`

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ main.py
â”œâ”€â”€ Utils/
â”‚   â”œâ”€â”€ detector.py
â”‚   â”œâ”€â”€ landmarks.py
â”‚   â””â”€â”€ helpers.py
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ deploy.prototxt
â”‚   â”œâ”€â”€ res10_300x300_ssd_iter_140000_fp16.caffemodel
â”‚   â””â”€â”€ lbfmodel.yaml
â”œâ”€â”€ video/
â”‚   â””â”€â”€ example.mp4
â””â”€â”€ output/
    â”œâ”€â”€ annotated.mp4
    â””â”€â”€ landmarks.csv
```

---

## ğŸ“ Notes

* Works best with **frontal faces**.
* Adjust `SKIP` parameter in `main.py` to balance performance vs. accuracy.
* EMA smoothing is on by default (`alpha = 0.7`).

---

## ğŸ“œ License

MIT License

---

## ğŸ”— Further Reading

A full technical breakdown is available in the accompanying blog post: \[BLOG\_URL\_PLACEHOLDER]
